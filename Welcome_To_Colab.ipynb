{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlccgkpol/makeMore/blob/main/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "4OccgyEDBaBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\",'r').read().splitlines()"
      ],
      "metadata": {
        "id": "Ldi-v-Jy0ykW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "FzvfmAOt-FKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = torch.zeros((27,27), dtype = torch.int32)\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  # print(chs,\"chs\")\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    N[stoi[ch1],stoi[ch2]]+=1\n",
        "    # print(ch1,ch2)"
      ],
      "metadata": {
        "id": "070txnQD9Y68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildDiagram(N):\n",
        "  plt.figure(figsize=(16,16))\n",
        "  plt.imshow(N, cmap = 'Blues')\n",
        "  for i in range(27):\n",
        "    for j in range(27):\n",
        "      chstr = itos[i] + itos[j]\n",
        "      plt.text(j,i,chstr, ha = \"center\", va = \"bottom\", color = 'gray')\n",
        "      plt.text(j,i,N[i,j].item(), ha = \"center\", va = \"top\", color = 'gray')\n",
        "  plt.axis(\"off\");"
      ],
      "metadata": {
        "id": "8B8C_J8A9iRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = (N + 100).float() #model smoothing and N+100 adds 100 to each element.\n",
        "print(P.shape)\n",
        "# P.sum(1,keepdim=True)\n",
        "P /= P.sum(1, keepdim=True)\n",
        "# 0 here means on 0th dimension, it will become 1 and it will sum across the column.\n",
        "# is it possible to divide [27,27] an [27,1]?? good point.\n",
        "\n",
        "# Broadcasting rules in pytorch ->\n",
        "\n",
        "# Each tensor has at least one dimension.\n",
        "# When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n"
      ],
      "metadata": {
        "id": "2wgFVS0MzyUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generateStrings(P):\n",
        "  q = torch.Generator().manual_seed(2147483647)\n",
        "  ix = 0\n",
        "  for i in range(5):\n",
        "    out = []\n",
        "    while True:\n",
        "      p = P[ix]\n",
        "      ix = torch.multinomial(p,num_samples=1,replacement=True,generator=q).item()\n",
        "      if ix == 0:\n",
        "        break;\n",
        "      out.append(itos[ix])\n",
        "    print(''.join(out))\n"
      ],
      "metadata": {
        "id": "qJdANstiwiXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 27,27\n",
        "# 27\n",
        "\n",
        "#27,27\n",
        "# 1,27 it will shift the 27 right.\n",
        "\n",
        "# so we will have problem instead of normalizing rows, we are normalizing column.\n",
        "\n",
        "# Thats why (keepdim = true) to get desired result when required."
      ],
      "metadata": {
        "id": "ysZMNUT-4Kd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in [\"rohit\"]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  logProb = 0;\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    prob = P[ix1,ix2]\n",
        "    logProb += -torch.log(prob)\n",
        "logProb/=3\n",
        "print(f'{ch1}{ch2} -> {prob:.4f} -> {logProb: .4f}')"
      ],
      "metadata": {
        "id": "ryBBo8Pi40LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minimize negative log likelihood."
      ],
      "metadata": {
        "id": "5mDc9eRc6HWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the training set of bigrams (x,y)\n",
        "xs,ys = [],[]\n",
        "\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  # print(chs,\"chs\")\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "zTOrZy-pCcCq"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60wf25BXEn5w",
        "outputId": "eecd6ae1-491f-4e0b-d126-ed3161ae0fed"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0,  5, 13, 13,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there are two ways to create tensor\n",
        "# torch.tensor\n",
        "# torch.Tensor"
      ],
      "metadata": {
        "id": "z2eskEQZEQnh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}